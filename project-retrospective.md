# LLM 기반 WAF 프로젝트 회고록
### 파이프라인 / 아키텍처 결정 과정: 시행착오와 의사결정

2025년 5월 ~ 2026년 2월 | 작성: 송연우


## 1. 들어가며

이 프로젝트는 'AI 기반 웹 방화벽'이라는 주제에서 출발해, 최종적으로 LLM을 파인튜닝하여 ModSecurity가 놓친 웹 공격을 탐지하고 커스텀 보안 룰을 자동 생성하는 시스템으로 구체화되었다. 이 글에서는 그 시행착오 과정을 기록한다.



## 2. 초기 구상: charCNN + Random Forest (5월)

### 2.1 첫 번째 아이디어

프로젝트 초반에는 머신러닝 기반 WAF라는 큰 방향만 있었고, 세 가지 모델 후보를 놓고 논의를 시작했다.

- Random Forest (scikit-learn)
- LightGBM
- DistilBERT (PyTorch)

HTTP 요청의 악성 페이로드는 문자 하나하나가 중요하다는 점에 착안해, character-level CNN으로 특징을 추출하고 Random Forest 분류기를 붙이는 경량 구조를 첫 아이디어로 잡았다. 대상은 XSS와 SQL Injection이었고, Kaggle 데이터셋을 활용하려 했다.

### 2.2 교수님 피드백 — 세션 기반 탐지로 방향 전환

0517 면담에서 교수님의 조언이 프로젝트 방향을 완전히 바꿨다. 단건 요청 분류가 아닌 '세션 흐름 기반 탐지'를 고려하라는 것이었다.

> 기존 WAF는 단건 요청을 정적 룰로 처리한다. 하지만 지능형 공격자는 한 세션 안에서 여러 요청으로 패턴을 분산시키는 경우가 많다. 세션 단위 누적 행동을 보지 않으면 탐지가 어렵다.

이 방향 전환이 이후 6개월의 핵심 전제가 되었다. charCNN + RF 구조는 보류되었다.

---

## 3. 첫 번째 아키텍처: ELK + LLM (6~7월 초)

### 3.1 설계 방향

세션 기반 탐지를 구현하기 위해 처음 설계한 아키텍처는 ELK 스택을 중심으로 한 구조였다.

- ModSecurity → Filebeat → Elasticsearch
- Python Cron 배치 → ES 조회 → 세션 그루핑 → 저장
- 세션 데이터 → Sentence Transformer → 벡터 임베딩 → ES 업데이트
- 관리자 질의 → 벡터 검색 → LLM 분석 → 응답

LLM에는 자연어 쿼리 기반 로그 조회, Kibana 보고서 보강, 시맨틱 검색, 커스텀 룰 생성 등 다양한 역할이 제안되었다. 기술 스택은 FastAPI + Llama 3 (Ollama) + React + Docker Compose로 상정했다.

### 3.2 ELK 제거 결정

0703 회의에서 ELK 스택 전체를 제외하기로 결정했다. 이유는 다음과 같다.

- **역할 모호**: 로그를 모으는 것 자체가 목표가 아니었고, ELK가 끼어들면서 LLM 역할이 더 불명확해짐
- **오버엔지니어링**: WAF 로그 → AI 모델 직접 연결이 단순하고 명확한 흐름
- **운영 복잡도**: 서비스가 많아질수록 팀 내 디버깅 비용이 기하급수적으로 증가

대신 자체 DB(이후 PostgreSQL + Prisma로 확정)를 사용하고, LLM은 Mistral 7B를 Ollama로 로컬 구동하는 방향으로 재설계했다.



## 4. 세션화 전략 — 구상과 폐기

### 4.1 왜 어려웠나

세션 기반 탐지를 하려면 '어떤 요청들을 하나의 세션으로 묶을 것인가'라는 정의가 먼저 필요했다. HTTP는 본질적으로 stateless하기 때문에 공식적인 세션 경계가 없다. 논의된 후보는 다음과 같다.

- IP + Port 조합 (초기 제안)
- IP + User-Agent + 30분 타임아웃 (논문 기반)
- 쿠키 기반 세션 ID (PHPSESSID 등)
- Source port 단독 (NAT 환경에서 한계 있음)

NAT 환경에서 하나의 공인 IP 뒤에 여러 사용자가 존재하거나, 공격자가 IP를 계속 바꾸면 세션 추적이 무력화된다는 구조적 한계가 있었다. 논문을 참고해 30분 타임아웃 + User-Agent 조합 기준을 잡고 세션화 스크립트를 작성했지만, 실험 단계에서 문제가 드러났다.

### 4.2 세션화 폐기 결정

실제로 데이터셋에 세션화를 적용해보니, 1000개 이상의 요청을 보냈을 때 세션으로 묶인 것이 20개 내외에 불과했다. 대부분의 요청이 단일 요청 단위 세션으로 인식되었다.

> 세션화 기준을 어떻게 잡더라도 데이터셋 특성상 대부분의 요청이 독립적 세션으로 분리되었다. '세션 흐름 기반 탐지'라는 개념은 유지하되, 실제 구현에서는 단일 로그 단위로 처리하는 방향으로 선회했다.

세션 ID 부여와 그룹핑 코드는 작성했고 DB에도 관련 컬럼을 유지했지만, 모델에 입력되는 실질적 단위는 단일 HTTP 요청 로그가 되었다. 이는 초기 설계에서 가장 큰 방향 수정이었다.



## 5. 모델 선택과 파인튜닝 전략

### 5.1 GPT → Mistral 7B 전환

초기에는 OpenAI GPT-3.5-turbo로 파인튜닝을 시도했다. 트레이닝 데이터 800세션, 에포크 2로 진행했지만 비용 문제와 코랩 세션 단절 문제가 반복되었다. 0916 회의 이후 Mistral 7B Instruct v0.3 오픈소스 모델로 전환했다.

| 항목 | GPT-3.5-turbo | Mistral 7B Instruct v0.3 |
|------|---------------|--------------------------|
| 비용 | 파인튜닝 유료 (지속 부담) | 무료 (LoRA) |
| 학습 환경 | OpenAI API | Google Colab / GPU 서버 |
| 추론 방식 | API 호출 | HuggingFace Inference Endpoint |
| 파인튜닝 방식 | Full fine-tuning | LoRA (PEFT) |

### 5.2 파인튜닝 시행착오

#### (1) 프롬프트 포맷 불일치

가장 오래 디버깅한 문제였다. 파인튜닝 시 사용한 포맷과 추론 시 포맷이 달랐다. Llama 3 스타일 특수 토큰(`<|begin_of_text|>` 등)을 Mistral에 잘못 적용하고 있었고, Mistral은 `[INST]` / `[/INST]` 포맷을 사용해야 했다.


#### (2) 과적합과 오탐 폭발

특정 시점에 Normal(정상) 클래스 탐지율이 51.6%에서 95.2%로 급등했다. 공격을 잘 잡는 게 아니라 정상 요청까지 공격으로 판단하는 과적합이었다. 해결을 위해 다음을 순차적으로 적용했다.

- LoRA rank 축소: r=16 → r=8 → r=4
- Dropout 증가: 0.1 → 0.2 → 0.4
- Learning rate 하향: 5e-5 → 3e-5 → 1e-5
- Weight decay 강화: 0.01 → 0.05 → 0.2
- Epoch 수 축소: 3 → 2 → 1
- 프롬프트에 보수적 전략 명시: '애매하면 Normal로 분류'

#### (3) 화이트리스트 필터 추가

모델 재학습만으로 오탐률이 충분히 낮아지지 않자, 추론 코드에 화이트리스트 필터를 추가하는 방식으로 보완했다. 이를 통해 오탐 687건에서 558건으로 129건을 보정했다.

### 5.3 모델 배포 전략 변경

학습 완료 후 배포가 또 다른 벽이었다. 교수님께 지원받은 GPU 서버는 디스크가 1GB 미만으로 7B 모델(약 13~15GB)을 올릴 수 없었고, RAM 기반 로딩은 SSH 재접속 시 모델이 사라지는 휘발성 문제가 있었다.

**최종 결정**: LoRA adapter를 HuggingFace Hub에 업로드하고, HuggingFace Inference Endpoint를 통해 GPU 리소스까지 HF 인프라에 위임했다. 백엔드는 HTTP 요청으로 추론 결과만 받는 구조로 단순화되었다.



## 6. 최종 파이프라인 확정

### 6.1 SaaS vs 온프레미스

0821 회의에서 배포 형태를 결정했다. 초기에는 중앙 서버 + 에이전트 방식의 SaaS를 상정했지만, 다음 이유로 온프레미스로 전환했다.

- 로그를 외부 서버로 전송하는 것에 대한 보안 우려
- 사용자 측 네트워크 설정의 복잡성
- Docker 이미지 배포로 내부망 완결성 확보 가능

### 6.2 최종 시스템 아키텍처

0925 교수님 피드백을 반영해 각 컴포넌트의 역할 경계가 명확하게 정리되었다.

| 단계 | 내용 |
|------|------|
| 1차 탐지 | ModSecurity (OWASP CRS) — 요청 수신 및 정적 룰 기반 탐지/차단, 로그 생성 |
| 로그 수집 | modsec_audit.log 파싱 → PostgreSQL RawLog 테이블 저장 |
| 2차 분류 | ModSecurity가 정상 통과시킨 트래픽에 대해 LLM이 2차 판단 (Normal / SQL Injection / Code Injection / Path Traversal) |
| 룰 생성 | 공격으로 분류된 세션 중 적용 룰이 없는 경우 생성 모델이 SecRule 형식 커스텀 룰 생성 (시험적 구현) |
| 관리자 UI | 탐지 현황 모니터링, AI 생성 룰 검토/승인/반려 |

핵심은 ModSecurity가 차단하지 못한 트래픽만 AI가 처리한다는 역할 분담이다. ModSecurity의 탐지 공백을 LLM이 메우는 구조가 최종적으로 확정되었다.



## 7. 실험 결과

### 7.1 ModSecurity 단독 탐지 성능

학습에 사용하지 않은 테스트 데이터셋 1000개(클래스별 250개)를 ModSecurity 단독 서버에 전송해 기준 성능을 측정했다.

| 공격 유형 | 탐지율 | 전체 정확도 | F1-score |
|-----------|--------|-------------|----------|
| Code Injection | 39.2% | 42% | 0.38 |
| SQL Injection | 10.4% | 42% | 0.38 |
| Path Traversal | 19.2% | 42% | 0.38 |
| 전체 (공격만) | 22.9% | 42% | 0.38 |

SQL Injection 탐지율이 10%에 불과했다. 분석 결과, 놓친 공격의 대부분이 URL 인코딩 및 문자 치환으로 난독화된 페이로드였다. ModSecurity의 시그니처 기반 룰이 이를 처리하지 못했고, 이것이 AI 2차 탐지 필요성의 근거가 되었다.

### 7.2 ModSecurity + AI 통합 성능 (최종)

화이트리스트 필터 보정을 적용한 최종 평가 결과다. 1000건 요청 중 558건이 AI 탐지로 처리되었으며, 필터 보정으로 오탐 129건을 제거했다.

| 지표 | ModSecurity 단독 | 통합 시스템 (최종) | 변화 |
|------|-----------------|-------------------|------|
| 전체 탐지율 | 30.1% | 55.8% | +25.7%p |
| Code Injection DR | 39.2% | 91.6% | +52.4%p |
| SQL Injection DR | 10.4% | 66.4% | +56.0%p |
| Path Traversal DR | 19.2% | 63.2% | +44.0%p |
| False Positive Rate | ~2% | 2.4% | +0.4%p (허용 범위) |

**오탐률 개선 과정**: 파인튜닝 초기 오탐률은 34%에 달했다. regularization 강화를 통해 14%로 낮췄고, 추론 코드에 화이트리스트 필터를 추가해 최종 2.4%까지 도달했다. 교수님이 반복적으로 강조한 '오탐률이 높은 시스템은 실용 배포가 불가능하다'는 원칙을 실험 수치로 확인한 과정이었다.

### 7.3 LLM 분류 모델의 의의

단순한 패턴 매칭이나 규칙 기반 탐지와 달리, LLM은 HTTP 요청의 문자열, 파라미터 구조, 코드 문맥을 의미적 수준에서 통합 해석할 수 있었다. 핵심 특징은 다음 두 가지다.

- **보수적 의사결정**: 공격 증거가 충분하지 않은 경우 판단을 보류하는 전략을 학습함. 기존 ML/룰 기반 WAF는 패턴 유무를 이진 판단하지만, LLM은 확률적 판단 주체로 동작한다.
- **의미적 해석**: URL 인코딩·난독화 등 변형된 페이로드에 대한 의미적 해석이 가능하다. ModSecurity가 놓친 SQL Injection 탐지율을 10%에서 66%로 끌어올린 핵심 요인이었다.



## 8. 룰 생성 모델 — 시험적 구현과 한계

### 8.1 설계 방향

0925 교수님 피드백에서 생성 모델의 역할이 구체화되었다. 단순히 공격 로그 하나에 룰 하나를 만드는 게 아니라, 같은 공격 타입으로 분류된 세션들을 묶어 공통 특징을 추출하고 최대한 일반적인(general) 룰을 만들자는 방향이었다.

- 이미 ModSecurity 룰이 적용된 공격 → 룰 생성 불필요
- AI가 공격으로 분류했지만 적용 룰이 없는 경우 → 새 룰 생성 대상

### 8.2 생성된 룰 구조

최종 파이프라인에서 생성된 룰은 2-레이어 구조를 가졌다.

```
SecRule TX:exec_hits "@ge 2" "id:300001,phase:2,pass,log,tag:'attack-rce',setvar:'tx.rce_score=+3'"
SecRule ARGS|REQUEST_BODY "@rx (\|\||&&|;|`|\$\()" "phase:2,pass,nolog"
```

첫 번째 룰(Gate rule)은 세션 수준에서 누적 공격 신호(`exec_hits`)를 확인하고, 두 번째 룰은 실제 페이로드에 shell 메타 문자가 존재하는지를 검증한다. 두 조건이 모두 충족될 때만 스코어가 누적되는 구조다.

클러스터별로 위험 점수를 차등 부여했다는 점도 특징이다. 같은 Code Injection이라도 클러스터 분석 결과에 따라 +1 ~ +10으로 스코어가 달라진다. 이는 단순 시그니처가 아닌 데이터 기반 세션 분석 결과를 WAF 룰로 변환하려는 시도였다.

### 8.3 한계와 포지셔닝

룰 생성 파이프라인은 완전히 안정화된 상태로 마무리되지 못했다. 생성된 룰의 정규식 정확도와 실제 ModSecurity 적용 시 동작 검증이 충분히 이루어지지 않았다.

> 룰 생성 모듈은 최종 시스템에서 '이런 방향으로 시도했다'는 개념 증명 수준으로 포지셔닝한다. 분류 모델의 탐지 결과를 WAF 언어로 변환하려는 설계 철학은 논문의 한계점 및 향후 연구 방향으로 기술한다.

---

## 9. 아키텍처 의사결정 요약

| 시기 | 결정 사항 | 당초 방향 | 변경 후 / 결과 |
|------|-----------|-----------|----------------|
| 5월 | 모델 구조 | charCNN + RF | LLM (Mistral 7B) 파인튜닝 |
| 7월 초 | 로그 관리 | ELK 스택 | 자체 DB (PostgreSQL + Prisma) |
| 7월 말 | 기반 모델 | GPT-3.5-turbo | Mistral 7B Instruct v0.3 (오픈소스) |
| 8월 | 배포 형태 | SaaS | 온프레미스 (Docker 이미지) |
| 9~10월 | 세션화 | IP+UA+시간 기반 그루핑 | 세션 ID 관리 유지, 실질 처리는 단일 로그 단위 |
| 11월 | 모델 서빙 | GPU 서버 로컬 로딩 | HuggingFace Inference Endpoint |
| 12월 | 탐지 전략 | 단독 AI 탐지 | ModSecurity + AI 2단계 탐지 |

---

## 10. 배운 것들

**프롬프트 포맷 일관성**: 파인튜닝 때 사용한 포맷과 추론 때 포맷이 다르면 성능이 급격히 떨어진다. Mistral은 `[INST]/[/INST]`, Llama 3는 `<|begin_of_text|>`처럼 모델마다 포맷이 다르다.

**오탐률 관리가 탐지율보다 중요하다**: 탐지율 96%에 오탐률 34%인 시스템은 실용 배포가 불가능하다. 오탐률 2.4%에 탐지율 60~90%인 시스템이 더 가치 있다. 보수적 분류 전략과 화이트리스트 필터를 통해 이 균형을 찾아가는 과정이 프로젝트 후반의 핵심이었다.

**좋은 아이디어도 구현 가능성을 검증해야 한다**: 세션화 전략은 이론적으로 타당했지만, 실제 데이터에 적용하니 대부분의 요청이 단일 세션으로 분리되었다. 아키텍처 설계 단계에서 프로토타입 검증을 먼저 했다면 설계 방향을 더 빨리 잡을 수 있었다.



## 11. 마치며

6개월간 아키텍처가 세 번 이상 바뀌었다. 처음에는 방향이 자꾸 바뀌는 것이 실패처럼 느껴졌지만, 각 전환점마다 더 정확한 문제 정의가 있었다. ELK를 버린 것, SaaS를 포기한 것, 세션화를 단일 로그로 축소한 것, GPT에서 Mistral로 간 것 모두 그 시점의 제약 조건과 목표를 반영한 결정이었다.

최종적으로 도달한 구조는 'ModSecurity가 놓친 공격을 LLM이 잡는 2단계 탐지 파이프라인'이다. 단순하고 명확하다. 좋은 아키텍처는 처음부터 설계되는 것이 아니라 시행착오를 통해 수렴한다는 것이 이 프로젝트에서 얻은 가장 교훈이다.
